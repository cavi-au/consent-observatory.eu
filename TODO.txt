

forbedringer af webscraber tool.

1. Improve scraper blocking workarounds: the more popular websites have ways to detect scrapers and block them,
which has stopped me from being able to collect data on them. I was hoping workarounds could be implemented.
Perhaps the Node-Unblocker library might be something easy to add? https://scrapfly.io/blog/web-scraping-with-node-unblocker/

2. URL resolution: the library currently doesn't cycle through different protocols when one of them doesn't work,
e.g., try both http, https, and www. I currently manually adjust this in the page-analyzer.js file ,
but it would be good if this could just be built in.

I think both of these adjustments would reduce the number of errors I currently get. I've attached a recent error log to show the kind of things I run into.
se zenhub fil fra midas


TODO disable submit button while submitting new analysis form, enable again when form change, e.g. when errors occur etc.

TODO unser /admin/status
vis alle jobs, og ved delete event fjern fra array af jobs der vises...


SE MIDAS email ang forside og about side..., der er også nogle asset filer...
lav også Help side se tlf..

web-scraper update
- update alle dependencies og test, få midas til at teste
- lav _ til #
- så den default'er til https i stedet for http ved ingen protokol, og så næste strategi er http
- test nogle af den fejl midas sendte, kan de afhjælpes?
- OPDATER user-agent til en nutidig, lav så den kan sættes som option
- push til npm, og integrer i denne app
